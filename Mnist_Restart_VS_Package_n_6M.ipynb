{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mnist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7-element Array{Float64,1}:\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra, NonNegLeastSquares, MLDatasets\n",
    "\n",
    "function alg_ours_with_restart(C::Matrix{Float64}, b::Matrix{Float64}, ϵ::Float64 )\n",
    "    extra_term_nnls = 0.5*norm(b)^2\n",
    "    m, n = size(C)\n",
    "    #number of times we restart\n",
    "    K = 50 #actually doesn't matter, since the restart_metric becomes really tiny pretty quickly \n",
    "    col_norm = norm.(eachcol(C))\n",
    "    inv_col_norm_square = 1.0 ./(col_norm.^2)\n",
    "    idx_seq = 1:n\n",
    "\n",
    "    x0 = zeros(n)\n",
    "    y0 = zeros(m)\n",
    "    z0 = zeros(m)\n",
    "\n",
    "    gamma = 30 #chosen after experiments on synthetic data\n",
    "    obj = 0 \n",
    "    \n",
    "    init_time = time()\n",
    "    for i=1:K\n",
    "\n",
    "        xktilde, yktilde, zktilde, new_metric, obj = alg_our_core(C, x0, y0, z0, m, n, inv_col_norm_square, idx_seq, ϵ, gamma, init_time, extra_term_nnls)\n",
    "\n",
    "        if (new_metric < ϵ)\n",
    "            break\n",
    "        end\n",
    "        x0[:] = xktilde[:]\n",
    "        y0[:] = yktilde[:]\n",
    "        z0[:] = zktilde[:]\n",
    "\n",
    "        gamma/= 2 # chosen after experiments on synthetic data \n",
    "    end\n",
    "    return obj\n",
    "end\n",
    "\n",
    "function alg_our_core(C, x0, y0, z0, m, n, inv_col_norm_square, idx_seq, ϵ, gamma, init_time, extra_term_nnls)\n",
    "        # reset all the scaling factors\n",
    "        previous_A = 1.0/n\n",
    "        previous_a = previous_A #a_1, A_1\n",
    "        a = 1.0/(n*n) # a_2\n",
    "        A = (n+1.0)/(n * n) # A_2\n",
    "\n",
    "\n",
    "        # compute x1 using the input x0\n",
    "        # we redefined phio(x) = 1/2 * ||x-x0||_A^2, hence updating x requires x0\n",
    "        # the step p(j)+=1/||A:j||^2 implicitly assumes ybar_0 = 0\n",
    "        # To allow for ybar_0 \\neq 0, we change p(j) a bit\n",
    "\n",
    "        ybar = copy(y0)\n",
    "        j = rand(idx_seq)\n",
    "        Aty0m = 1 - dot(ybar, C[:, j]) #                                     dot(̄ȳ, C[:, j])\n",
    "\n",
    "        p = copy(x0)\n",
    "        x = copy(x0)\n",
    "        p[j] += inv_col_norm_square[j]*Aty0m\n",
    "        x[j] = min(inv_col_norm_square[j], max(0, p[j])) #x and x0 differ only at j\n",
    "\n",
    "        # compute y1\n",
    "        # note that y0^(R) and y1^(R) are independent of each othre\n",
    "        # y1^(R) = Ax1^(R) = Ax0^(R) + A*(x1^R - x0^R) = z0^R + A*(x1^R - x0^R)\n",
    "        # y0^R may be chosen to be either ytildeK or 0 (our analysis uses 0)\n",
    "        # Further note that if y0^R = ytildeK, then we must ALSO choose ybar_0 = ytildeK, and\n",
    "        # this changes how x is init.\n",
    "        previous_y = copy(y0)\n",
    "        z = copy(z0)\n",
    "        z += C[:, j] * (x[j] - x0[j]) # z_1 = A x_1 = A (x_0 + (x_1 - x_0))\n",
    "        y = copy(z) # y_1 = A xtilde1 = A x_1 = z_1\n",
    "\n",
    "        # compute ȳ, ỹ (because we need to return it), and some auxiliary variables\n",
    "        ybar[:] = y[:] + previous_a/a * (y[:] - previous_y[:]) #ybar_1\n",
    "        s = zeros(n) # need this so that xtildek = xk + sk/Ak; s_1 = 0 (see Chaobing's lemma for why this is needed)\n",
    "        ỹ = copy(y) # ytildek = convex comb of yi's, so ytilde1 = y1\n",
    "\n",
    "        # restart value init; -1^{\\top}x+0.5\\|Ax\\|^{2}+.5*\\|y\\|^{2}+\\frac{1}{2\\epsilon}\\|(-A^{\\top}y+1)^{+}\\|^{2}\n",
    "        restart_coeff = 5000\n",
    "        Atym = -C'*y0 .+ 1\n",
    "        truncated_Atym = ((Atym) .> 0).*Atym\n",
    "        restart_val_prev = -sum(x0)+ 0.5* norm(z0)^2 +0.5*norm(y0)^2 + restart_coeff*norm(truncated_Atym)^2\n",
    "        restart_val_curr = restart_val_prev\n",
    "\n",
    "        # inits for restart\n",
    "        iter_count = 0\n",
    "        Flag = true\n",
    "        Ax0 = zeros(m)\n",
    "        new_metric = 0 \n",
    "        obj = 0 \n",
    "    \n",
    "        while (Flag)\n",
    "\n",
    "            # updates related to x\n",
    "            j = rand(idx_seq)\n",
    "            p[j] += - n * inv_col_norm_square[j] * a * (sum(C[:,j] .* ybar) - 1)\n",
    "            prev_xj = x[j]\n",
    "            x[j] = min(inv_col_norm_square[j], max(0, p[j]))\n",
    "            # update s so that we may return xtildek at only O(1) cost\n",
    "            s[j] += ((n-1) * a -  previous_A) * (x[j] - prev_xj)\n",
    "\n",
    "            # updates related to y\n",
    "            previous_y[:] = y[:]\n",
    "            z[:] += C[:, j] * (x[j] - prev_xj)\n",
    "            y[:] = previous_A/A * y[:] + a/A * z[:] + (n-1) * a/A * (x[j] - prev_xj) * C[:,j]\n",
    "            # need to update ytilde each time because that's what we want to return,\n",
    "            # and we aren't saving all the yi's.\n",
    "            ỹ[:] = previous_A/A * ỹ[:] + a/A * y[:]\n",
    "\n",
    "            # update scaling factors\n",
    "            previous_a, previous_A = a, A\n",
    "            a = min(n * a/(n-1), sqrt(A)/(2*n))\n",
    "            A += a\n",
    "\n",
    "            # update ȳ (note that ȳ_k depends on a_k and a_{k+1})\n",
    "            ybar[:] = y[:] + previous_a/a * (y[:] - previous_y[:])\n",
    "\n",
    "            # restart stuff\n",
    "            iter_count+=1\n",
    "            # Since we are computing the restart condition without any optimizations,\n",
    "            # and the restart condition likely involves (expensive) matrix-vector products,\n",
    "            # we check it only after a certain number of iters have passed.\n",
    "\n",
    "            if (iter_count % ceil(n*gamma) ==0)\n",
    "                # compute the restart metric \n",
    "                # note that we DO use the restart metric to terminate the OUTER ALG, \n",
    "                # , even though we are doing fixed restarts in the INNER ALG \n",
    "                Atym = -C'*ỹ .+ 1\n",
    "                truncated_Atym = ((Atym) .> 0).*Atym\n",
    "                sumx0 = sum(x + (1.0/previous_A) * s)\n",
    "                Ax0 = C*(x + (1.0/previous_A) * s)\n",
    "                new_metric = norm(truncated_Atym)^2\n",
    "\n",
    "                # For now, we are doing fixed restarts.\n",
    "                obj = extra_term_nnls-sumx0+ 0.5* norm(Ax0)^2\n",
    "                print(\"\\n\\n Obj = \", obj, \", time since init = \", time() - init_time, \", new metric = \", new_metric)\n",
    "                print(\"\\n\")\n",
    "                Flag = false\n",
    "                # end\n",
    "            end\n",
    "        end\n",
    "        return x + (1.0/previous_A) * s, ỹ, Ax0, new_metric, obj\n",
    "end\n",
    "\n",
    "\n",
    "train_x, train_y = MNIST.traindata()\n",
    "A = Array{Int64}\n",
    "b = Array{Int64}\n",
    "A_init = reshape(train_x,7,4*28*60000)\n",
    "#b = train_y\n",
    "b=ones(7)\n",
    "#test_x,  test_y  = MNIST.testdata()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " nnls package value is 1.60237371373018e-31, and time is   0.781993 seconds (59 allocations: 207.629 MiB, 2.71% gc time)\n"
     ]
    }
   ],
   "source": [
    "function alg_lawsonhanson(A, b)\n",
    "    xnnls = nonneg_lsq(A,b;alg=:nnls)  # NNLS\n",
    "\n",
    "    nnls_optval = 0.5*norm(A*xnnls - b)^2\n",
    "    \n",
    "    print(\"\\n\\n nnls package value is \", nnls_optval, \", and time is \")\n",
    "end\n",
    "\n",
    "function remove_col1(A,b)#Chenghui has an idea to optimize this for speed (\"filter\")\n",
    "    s=A'*b # n*1\n",
    "    B=A[:,vec(s.>0)] # m*b matrix where b is smaller than n\n",
    "    s=s[vec(s.>0)] # s is b*1 in dimensions\n",
    "    return B./s'\n",
    "end\n",
    "\n",
    "\n",
    "A= remove_col1(A_init,b)\n",
    "A = Float64.(A)\n",
    "b = Float64.(b)\n",
    "\n",
    "\n",
    "\n",
    "@time begin\n",
    "    xnnls = nonneg_lsq(A,b;alg=:nnls)  # NNLS\n",
    "    nnls_optval = 0.5*norm( A*xnnls - b)^2\n",
    "    print(\"\\n\\n nnls package value is \", nnls_optval, \", and time is \")\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Obj = -7.105427357601002e-15, time since init = 244.95700001716614, new metric = 7.085683213586454e-8\n",
      "\n",
      "\n",
      " Our result with restart is -7.105427357601002e-15, and time is 245.269954 seconds (1.86 G allocations: 249.524 GiB, 5.57% gc time)\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.00001 \n",
    "@time begin\n",
    "     our_result = alg_ours_with_restart(A, vcat(b'),epsilon)\n",
    "     print(\"\\n\\n Our result with restart is \", our_result, \", and time is \")\n",
    " end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 6720000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(A_init)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
